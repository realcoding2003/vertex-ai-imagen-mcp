#!/usr/bin/env python3
"""
Google Cloud Vertex AI Imagen MCP Server

ğŸ¨ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” MCP ì„œë²„

Author: Claude & Kevin Park
License: MIT
Version: 1.0.0
"""

import asyncio
import base64
import json
import os
import sys
import logging
from typing import Any, Dict, List, Optional
from datetime import datetime

# Google Cloud ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import requests
    from google.oauth2 import service_account
    from google.auth.transport.requests import Request
except ImportError:
    print("âŒ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
    print("pip install requests google-auth google-auth-oauthlib google-auth-httplib2")
    sys.exit(1)

# MCP ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì‚¬í•­)
try:
    from mcp.server import Server
    from mcp.server.models import InitializationOptions
    from mcp.server.stdio import stdio_server
    from mcp.types import (
        CallToolRequest, CallToolResult, ListToolsRequest, ListToolsResult,
        Tool, TextContent, ImageContent, EmbeddedResource
    )
    HAS_MCP = True
except ImportError:
    HAS_MCP = False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class VertexAIImagenClient:
    """Vertex AI Imagen API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, project_id: str, location: str = "us-central1"):
        self.project_id = project_id
        self.location = location
        self.credentials = None
        self.base_url = f"https://{location}-aiplatform.googleapis.com/v1"
        
        # ì§€ì›ë˜ëŠ” ëª¨ë¸ ëª©ë¡
        self.supported_models = [
            "imagegeneration@006",
            "imagegeneration@005", 
            "imagegeneration@002",
            "imagen-3.0-generate-001",
            "imagen-3.0-generate-002",
            "imagen-3.0-fast-generate-001"
        ]
        
    def setup_credentials(self, service_account_path: str) -> bool:
        """ì„œë¹„ìŠ¤ ê³„ì • í‚¤ë¡œ ì¸ì¦ ì„¤ì •"""
        try:
            if not os.path.exists(service_account_path):
                raise FileNotFoundError(f"ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {service_account_path}")
            
            self.credentials = service_account.Credentials.from_service_account_file(
                service_account_path,
                scopes=['https://www.googleapis.com/auth/cloud-platform']
            )
            
            if not self.credentials.valid:
                self.credentials.refresh(Request())
            
            logger.info("âœ… Google Cloud ì¸ì¦ ì„±ê³µ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì¸ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    async def generate_image(self, **kwargs) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ìƒì„±"""
        prompt = kwargs.get("prompt")
        model_version = kwargs.get("model_version", "imagegeneration@006")
        image_count = kwargs.get("image_count", 1)
        aspect_ratio = kwargs.get("aspect_ratio", "1:1")
        
        # ëª¨ë¸ ë²„ì „ ê²€ì¦
        if model_version not in self.supported_models:
            raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸: {model_version}. ì§€ì› ëª¨ë¸: {self.supported_models}")
        
        url = (
            f"{self.base_url}/projects/{self.project_id}/locations/{self.location}/"
            f"publishers/google/models/{model_version}:predict"
        )
        
        # ìš”ì²­ ë°ì´í„° êµ¬ì„±
        request_data = {
            "instances": [{"prompt": prompt}],
            "parameters": {
                "sampleCount": min(image_count, 4),
                "aspectRatio": aspect_ratio,
                "addWatermark": kwargs.get("add_watermark", False)
            }
        }
        
        # ì„ íƒì  ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
        if kwargs.get("negative_prompt"):
            request_data["parameters"]["negativePrompt"] = kwargs["negative_prompt"]
        
        if kwargs.get("safety_setting"):
            request_data["parameters"]["safetySetting"] = kwargs["safety_setting"]
        
        if kwargs.get("enhance_prompt", True):
            request_data["parameters"]["enhancePrompt"] = True
        
        if kwargs.get("seed") is not None:
            request_data["parameters"]["seed"] = kwargs["seed"]
            request_data["parameters"]["addWatermark"] = False  # ì‹œë“œ ì‚¬ìš©ì‹œ ì›Œí„°ë§ˆí¬ ë¹„í™œì„±í™”
        
        headers = {
            "Authorization": f"Bearer {self.credentials.token}",
            "Content-Type": "application/json"
        }
        
        try:
            logger.info(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„±: {prompt[:50]}...")
            
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, 
                lambda: requests.post(url, json=request_data, headers=headers, timeout=180)
            )
            
            if response.status_code != 200:
                error_message = f"HTTP {response.status_code}: {response.text}"
                logger.error(f"âŒ API ì˜¤ë¥˜: {error_message}")
                raise Exception(error_message)
            
            result = response.json()
            logger.info(f"âœ… ìƒì„± ì™„ë£Œ: {len(result.get('predictions', []))}ê°œ ì´ë¯¸ì§€")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

if HAS_MCP:
    # ì‹¤ì œ MCP ì„œë²„ êµ¬í˜„
    class ImagenMCPServer:
        def __init__(self):
            self.server = Server("vertex-ai-imagen")
            self.client = None
            self.setup_handlers()

        def setup_handlers(self):
            @self.server.list_tools()
            async def handle_list_tools() -> ListToolsResult:
                return ListToolsResult(
                    tools=[
                        Tool(
                            name="generate_image",
                            description="í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±",
                            inputSchema={
                                "type": "object",
                                "properties": {
                                    "prompt": {
                                        "type": "string",
                                        "description": "ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸"
                                    },
                                    "negative_prompt": {
                                        "type": "string",
                                        "description": "í”¼í•˜ê³  ì‹¶ì€ ë‚´ìš© (ì„ íƒì‚¬í•­)"
                                    },
                                    "image_count": {
                                        "type": "integer",
                                        "minimum": 1,
                                        "maximum": 4,
                                        "default": 1,
                                        "description": "ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜"
                                    },
                                    "aspect_ratio": {
                                        "type": "string",
                                        "enum": ["1:1", "3:4", "4:3", "16:9", "9:16"],
                                        "default": "1:1",
                                        "description": "ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨"
                                    },
                                    "model_version": {
                                        "type": "string",
                                        "enum": [
                                            "imagegeneration@006",
                                            "imagegeneration@005", 
                                            "imagen-3.0-generate-001",
                                            "imagen-3.0-generate-002",
                                            "imagen-3.0-fast-generate-001"
                                        ],
                                        "default": "imagegeneration@006",
                                        "description": "ì‚¬ìš©í•  ëª¨ë¸ ë²„ì „"
                                    },
                                    "safety_setting": {
                                        "type": "string",
                                        "enum": [
                                            "block_low_and_above",
                                            "block_medium_and_above", 
                                            "block_only_high"
                                        ],
                                        "default": "block_medium_and_above",
                                        "description": "ì•ˆì „ í•„í„° ìˆ˜ì¤€"
                                    },
                                    "seed": {
                                        "type": "integer",
                                        "description": "ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ê°’ (ì„ íƒì‚¬í•­)"
                                    }
                                },
                                "required": ["prompt"]
                            }
                        ),
                        Tool(
                            name="list_models",
                            description="ì‚¬ìš© ê°€ëŠ¥í•œ Imagen ëª¨ë¸ ëª©ë¡ ì¡°íšŒ",
                            inputSchema={
                                "type": "object",
                                "properties": {},
                                "required": []
                            }
                        )
                    ]
                )

            @self.server.call_tool()
            async def handle_call_tool(name: str, arguments: Dict[str, Any]) -> CallToolResult:
                try:
                    if name == "generate_image":
                        return await self._generate_image(**arguments)
                    elif name == "list_models":
                        return await self._list_models()
                    else:
                        raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {name}")
                except Exception as e:
                    logger.error(f"ë„êµ¬ í˜¸ì¶œ ì˜¤ë¥˜: {e}")
                    return CallToolResult(
                        content=[TextContent(type="text", text=f"âŒ ì˜¤ë¥˜: {str(e)}")]
                    )

        async def _generate_image(self, **kwargs) -> CallToolResult:
            """ì´ë¯¸ì§€ ìƒì„± ì²˜ë¦¬"""
            if not self.client:
                raise Exception("í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            prompt = kwargs.get("prompt")
            result = await self.client.generate_image(**kwargs)

            content = []
            content.append(TextContent(
                type="text",
                text=f"âœ… {len(result.get('predictions', []))}ê°œì˜ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\ní”„ë¡¬í”„íŠ¸: {prompt}"
            ))

            # ìƒì„±ëœ ì´ë¯¸ì§€ë“¤ì„ ì‘ë‹µì— ì¶”ê°€
            for i, prediction in enumerate(result.get("predictions", [])):
                if "bytesBase64Encoded" in prediction:
                    image_data = prediction["bytesBase64Encoded"]
                    mime_type = prediction.get("mimeType", "image/png")
                    
                    content.append(ImageContent(
                        type="image",
                        data=image_data,
                        mimeType=mime_type
                    ))
                    
                    # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
                    if prediction.get("prompt"):
                        content.append(TextContent(
                            type="text",
                            text=f"ğŸ“ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ {i+1}: {prediction['prompt']}"
                        ))

            return CallToolResult(content=content)

        async def _list_models(self) -> CallToolResult:
            """ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
            if not self.client:
                raise Exception("í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            models_info = []
            for model in self.client.supported_models:
                if "imagen-3.0" in model:
                    description = "Imagen 3.0 - ìµœì‹  ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±"
                    if "fast" in model:
                        description += " (ë¹ ë¥¸ ìƒì„±)"
                else:
                    description = f"Imagen {model.split('@')[1]} - ì•ˆì •ì ì¸ ì´ë¯¸ì§€ ìƒì„±"
                
                models_info.append(f"â€¢ {model}: {description}")
            
            content = [TextContent(
                type="text", 
                text=f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ({len(self.client.supported_models)}ê°œ):\n\n" + "\n".join(models_info)
            )]
            
            return CallToolResult(content=content)

        async def run(self):
            """MCP ì„œë²„ ì‹¤í–‰"""
            # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
            project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
            location = os.getenv("VERTEX_AI_LOCATION", "us-central1")
            credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

            if not project_id or not credentials_path:
                logger.error("í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                logger.error("GOOGLE_CLOUD_PROJECTì™€ GOOGLE_APPLICATION_CREDENTIALSë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")
                sys.exit(1)

            # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            self.client = VertexAIImagenClient(project_id, location)
            
            if not self.client.setup_credentials(credentials_path):
                logger.error("ì¸ì¦ ì„¤ì • ì‹¤íŒ¨")
                sys.exit(1)

            logger.info("ğŸš€ Vertex AI Imagen MCP Server ì‹œì‘")
            logger.info(f"í”„ë¡œì íŠ¸: {project_id}")
            logger.info(f"ìœ„ì¹˜: {location}")
            
            # MCP ì„œë²„ ì‹¤í–‰
            async with stdio_server() as (read_stream, write_stream):
                await self.server.run(read_stream, write_stream, InitializationOptions())

else:
    # MCP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì„ ë•Œì˜ ë…ë¦½ ì‹¤í–‰ ëª¨ë“œ
    class ImagenMCPServer:
        def __init__(self):
            self.client = None

        async def initialize(self):
            """ì„œë²„ ì´ˆê¸°í™”"""
            project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
            location = os.getenv("VERTEX_AI_LOCATION", "us-central1")
            credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

            if not project_id:
                print("âŒ GOOGLE_CLOUD_PROJECT í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                print("ì˜ˆì‹œ: export GOOGLE_CLOUD_PROJECT='your-project-id'")
                raise Exception("í™˜ê²½ ë³€ìˆ˜ ë¯¸ì„¤ì •")

            if not credentials_path:
                print("âŒ GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                print("ì˜ˆì‹œ: export GOOGLE_APPLICATION_CREDENTIALS='/path/to/service-account-key.json'")
                raise Exception("í™˜ê²½ ë³€ìˆ˜ ë¯¸ì„¤ì •")

            self.client = VertexAIImagenClient(project_id, location)
            
            if not self.client.setup_credentials(credentials_path):
                raise Exception("ì¸ì¦ ì„¤ì • ì‹¤íŒ¨")

            logger.info("ğŸš€ Imagen MCP Server (ë…ë¦½ ëª¨ë“œ) ì´ˆê¸°í™” ì™„ë£Œ")
            logger.info(f"í”„ë¡œì íŠ¸: {project_id}")
            logger.info(f"ìœ„ì¹˜: {location}")
            logger.info(f"ì§€ì› ëª¨ë¸: {', '.join(self.client.supported_models)}")

        async def generate_image_interactive(self):
            """ëŒ€í™”í˜• ì´ë¯¸ì§€ ìƒì„±"""
            print(f"\nğŸ¨ Vertex AI Imagen ì´ë¯¸ì§€ ìƒì„±ê¸°")
            print("ëª…ë ¹ì–´: 'quit' (ì¢…ë£Œ), 'models' (ëª¨ë¸ ëª©ë¡)")
            
            while True:
                try:
                    print("\n" + "="*60)
                    
                    command = input("ëª…ë ¹ì–´ ë˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
                    
                    if command.lower() == 'quit':
                        print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        break
                    
                    if command.lower() == 'models':
                        print("\nğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
                        for model in self.client.supported_models:
                            if "imagen-3.0" in model:
                                desc = "ìµœì‹  ê³ í’ˆì§ˆ ëª¨ë¸"
                                if "fast" in model:
                                    desc += " (ë¹ ë¥¸ ìƒì„±)"
                            else:
                                desc = f"ì•ˆì •ì ì¸ ëª¨ë¸ v{model.split('@')[1]}"
                            print(f"  â€¢ {model}: {desc}")
                        continue
                    
                    if not command:
                        print("âŒ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                        continue
                    
                    prompt = command
                    
                    # ì¶”ê°€ ì˜µì…˜ ì…ë ¥
                    print(f"\nğŸ“‹ ì¶”ê°€ ì˜µì…˜ (Enterë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©):")
                    
                    image_count = input("ì´ë¯¸ì§€ ìˆ˜ (1-4, ê¸°ë³¸ê°’: 1): ").strip()
                    image_count = int(image_count) if image_count.isdigit() else 1
                    image_count = min(max(image_count, 1), 4)
                    
                    aspect_ratio = input("ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ (1:1, 16:9, 9:16 ë“±, ê¸°ë³¸ê°’: 1:1): ").strip()
                    if aspect_ratio not in ["1:1", "3:4", "4:3", "16:9", "9:16"]:
                        aspect_ratio = "1:1"
                    
                    model_version = input(f"ëª¨ë¸ (ê¸°ë³¸ê°’: imagegeneration@006): ").strip()
                    if model_version not in self.client.supported_models:
                        model_version = "imagegeneration@006"
                    
                    negative_prompt = input("ì œì™¸í•  ë‚´ìš© (ì„ íƒì‚¬í•­): ").strip() or None
                    
                    print(f"\nğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
                    print(f"  ğŸ“ í”„ë¡¬í”„íŠ¸: {prompt}")
                    print(f"  ğŸ”¢ ê°œìˆ˜: {image_count}")
                    print(f"  ğŸ“ ë¹„ìœ¨: {aspect_ratio}")
                    print(f"  ğŸ¤– ëª¨ë¸: {model_version}")
                    
                    start_time = datetime.now()
                    
                    # ì´ë¯¸ì§€ ìƒì„±
                    result = await self.client.generate_image(
                        prompt=prompt,
                        image_count=image_count,
                        aspect_ratio=aspect_ratio,
                        model_version=model_version,
                        negative_prompt=negative_prompt
                    )
                    
                    generation_time = (datetime.now() - start_time).total_seconds()
                    
                    # ê²°ê³¼ ì²˜ë¦¬
                    predictions = result.get("predictions", [])
                    if predictions:
                        print(f"\nâœ… {len(predictions)}ê°œ ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ! (ì†Œìš”ì‹œê°„: {generation_time:.1f}ì´ˆ)")
                        
                        # ì´ë¯¸ì§€ ì €ì¥
                        for i, prediction in enumerate(predictions):
                            if "bytesBase64Encoded" in prediction:
                                image_data = base64.b64decode(prediction["bytesBase64Encoded"])
                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                safe_prompt = "".join(c for c in prompt[:20] if c.isalnum() or c in (' ', '-', '_')).rstrip()
                                filename = f"imagen_{timestamp}_{safe_prompt.replace(' ', '_')}_{i+1}.png"
                                
                                # í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì €ì¥
                                filepath = os.path.join(os.getcwd(), filename)
                                
                                with open(filepath, "wb") as f:
                                    f.write(image_data)
                                
                                file_size = os.path.getsize(filepath)
                                print(f"  ğŸ’¾ ì €ì¥ë¨: {filename} ({file_size:,} bytes)")
                                
                                # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
                                if prediction.get("prompt"):
                                    print(f"  ğŸ“ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ {i+1}: {prediction['prompt']}")
                    else:
                        print("âŒ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        print(f"ì‘ë‹µ: {result}")
                        
                except KeyboardInterrupt:
                    print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                except Exception as e:
                    print(f"âŒ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    server = ImagenMCPServer()
    
    if HAS_MCP:
        # MCP ëª¨ë“œë¡œ ì‹¤í–‰
        logger.info("MCP ì„œë²„ ëª¨ë“œë¡œ ì‹¤í–‰")
        await server.run()
    else:
        # ë…ë¦½ ì‹¤í–‰ ëª¨ë“œ
        logger.info("ë…ë¦½ ì‹¤í–‰ ëª¨ë“œë¡œ ì‹œì‘")
        try:
            await server.initialize()
            await server.generate_image_interactive()
        except Exception as e:
            print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            sys.exit(1)

if __name__ == "__main__":
    print("ğŸ¨ Vertex AI Imagen MCP Server v1.0.0")
    print("=" * 50)
    
    if not HAS_MCP:
        print("âš ï¸ MCP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ë…ë¦½ ì‹¤í–‰ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
        print("MCP í†µí•©ì„ ìœ„í•´ì„œëŠ” 'pip install mcp' ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\n")
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
    credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    
    if not project_id or not credentials_path:
        print("âŒ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤:")
        if not project_id:
            print("  - GOOGLE_CLOUD_PROJECT")
        if not credentials_path:
            print("  - GOOGLE_APPLICATION_CREDENTIALS")
        print("\nì„¤ì • ì˜ˆì‹œ:")
        print("export GOOGLE_CLOUD_PROJECT='your-project-id'")
        print("export GOOGLE_APPLICATION_CREDENTIALS='/path/to/service-account-key.json'")
        print("export VERTEX_AI_LOCATION='us-central1'")
        sys.exit(1)
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ì„œë²„ ì¢…ë£Œ")
    except Exception as e:
        print(f"âŒ ì„œë²„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)
