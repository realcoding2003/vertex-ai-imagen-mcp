#!/usr/bin/env python3
"""
Google Cloud Vertex AI Imagen MCP Server (Simple Version)

ğŸ¨ vertex-ai-imagen íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•œ ê°„ë‹¨í•œ MCP ì„œë²„

Author: Kevin Park
License: MIT
Version: 2.0.0
"""

import asyncio
import json
import os
import sys
import logging
from typing import Any, Dict, List, Optional
from datetime import datetime

# vertex-ai-imagen íŒ¨í‚¤ì§€
try:
    from vertex_ai_imagen import ImagenClient
except ImportError:
    # MCP ëª¨ë“œì—ì„œëŠ” ì¡°ìš©íˆ ì¢…ë£Œ
    if not sys.stdin.isatty():
        sys.exit(1)
    print("âŒ vertex-ai-imagen íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:", file=sys.stderr)
    print("pip install vertex-ai-imagen", file=sys.stderr)
    sys.exit(1)

# ë¡œê¹… ì„¤ì • - stderrë¡œë§Œ ì¶œë ¥
logging.basicConfig(
    level=logging.ERROR,  # ERROR ë ˆë²¨ë§Œ ì¶œë ¥
    format='%(asctime)s - %(levelname)s - %(message)s',
    stream=sys.stderr  # stderrë¡œ ì¶œë ¥
)
logger = logging.getLogger(__name__)

# ì „ì—­ í´ë¼ì´ì–¸íŠ¸
imagen_client = None

async def initialize_client():
    """ImagenClient ì´ˆê¸°í™”"""
    global imagen_client
    
    project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
    if not project_id:
        raise ValueError("GOOGLE_CLOUD_PROJECT í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    imagen_client = ImagenClient(project_id=project_id)
    
    # ì¸ì¦ ì„¤ì •
    credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    if credentials_path and os.path.exists(credentials_path):
        imagen_client.setup_credentials(credentials_path)
    else:
        # í™˜ê²½ì—ì„œ ê¸°ë³¸ ì¸ì¦ ì‹œë„
        try:
            imagen_client.setup_credentials_from_env()
        except Exception:
            # ì¸ì¦ ì‹¤íŒ¨ ì‹œ ì¡°ìš©íˆ ì²˜ë¦¬
            pass

async def handle_generate_image(params: Dict[str, Any]) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ ìƒì„± ì²˜ë¦¬"""
    try:
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í™•ì¸
        global imagen_client
        if not imagen_client:
            await initialize_client()
        
        # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ
        prompt = params.get("prompt", "")
        if not prompt:
            return {
                "content": [
                    {
                        "type": "text",
                        "text": "âŒ ì˜¤ë¥˜: promptëŠ” í•„ìˆ˜ ë§¤ê°œë³€ìˆ˜ì…ë‹ˆë‹¤."
                    }
                ]
            }
        
        kwargs = {
            "prompt": prompt,
            "count": min(params.get("count", 1), 4),
            "aspect_ratio": params.get("aspect_ratio", "1:1"),
            "model": params.get("model", "imagegeneration@006"),
            "safety_setting": params.get("safety_setting", "block_some")
        }
        
        if params.get("negative_prompt"):
            kwargs["negative_prompt"] = params["negative_prompt"]
        
        if params.get("seed") is not None:
            kwargs["seed"] = params["seed"]
        
        # ì´ë¯¸ì§€ ìƒì„±
        result = await imagen_client.generate(**kwargs)
        
        # ê²°ê³¼ ì²˜ë¦¬
        if isinstance(result, list):
            images = result
        else:
            images = [result]
        
        # ì €ì¥ ì²˜ë¦¬
        saved_files = []
        save_path = params.get("save_path")
        if save_path:
            os.makedirs(save_path, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename_prefix = params.get("filename_prefix", "generated_image")
            
            for i, image in enumerate(images):
                filename = f"{filename_prefix}_{timestamp}_{i+1}.png"
                filepath = os.path.join(save_path, filename)
                image.save(filepath)
                saved_files.append(filepath)
        
        # ê²°ê³¼ êµ¬ì„±
        result_text = f"âœ… {len(images)}ê°œ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!\n\n"
        
        for i, image in enumerate(images):
            result_text += f"ğŸ¨ ì´ë¯¸ì§€ {i+1}: {image.size:,} bytes\n"
        
        if saved_files:
            result_text += f"\nğŸ“ ì €ì¥ëœ íŒŒì¼ë“¤:\n"
            for filepath in saved_files:
                result_text += f"  ğŸ“ {filepath}\n"
        else:
            result_text += "\nğŸ’¡ save_pathë¥¼ ì§€ì •í•˜ë©´ íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.\n"
        
        # í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜ (ì´ë¯¸ì§€ëŠ” ì¼ë‹¨ ì œì™¸)
        response_content = [{"type": "text", "text": result_text}]
        
        return {"content": response_content}
        
    except Exception as e:
        return {
            "content": [
                {
                    "type": "text", 
                    "text": f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}"
                }
            ]
        }

async def handle_list_models() -> Dict[str, Any]:
    """ëª¨ë¸ ëª©ë¡ ì²˜ë¦¬"""
    try:
        global imagen_client
        if not imagen_client:
            await initialize_client()
        
        models = imagen_client.list_models()
        model_list = "\n".join([f"â€¢ {model}" for model in models])
        result_text = f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ Imagen ëª¨ë¸:\n\n{model_list}"
        
        return {"content": [{"type": "text", "text": result_text}]}
        
    except Exception as e:
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
                }
            ]
        }

async def handle_message(message: Dict[str, Any]) -> Dict[str, Any]:
    """ë©”ì‹œì§€ ì²˜ë¦¬"""
    try:
        method = message.get("method")
        params = message.get("params", {})
        
        if method == "initialize":
            return {
                "jsonrpc": "2.0",
                "id": message.get("id"),
                "result": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {
                        "tools": {}
                    },
                    "serverInfo": {
                        "name": "vertex-ai-imagen",
                        "version": "2.0.0"
                    }
                }
            }
        
        elif method == "notifications/initialized":
            # ì´ˆê¸°í™” ì™„ë£Œ ì•Œë¦¼ - ì‘ë‹µ ë¶ˆí•„ìš”
            return None
        
        elif method == "tools/list":
            return {
                "jsonrpc": "2.0",
                "id": message.get("id"),
                "result": {
                    "tools": [
                        {
                            "name": "generate_image",
                            "description": "í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±",
                            "inputSchema": {
                                "type": "object",
                                "properties": {
                                    "prompt": {
                                        "type": "string",
                                        "description": "ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸"
                                    },
                                    "negative_prompt": {
                                        "type": "string",
                                        "description": "í”¼í•˜ê³  ì‹¶ì€ ë‚´ìš© (ì„ íƒì‚¬í•­)"
                                    },
                                    "count": {
                                        "type": "integer",
                                        "minimum": 1,
                                        "maximum": 4,
                                        "default": 1,
                                        "description": "ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜"
                                    },
                                    "aspect_ratio": {
                                        "type": "string",
                                        "enum": ["1:1", "3:4", "4:3", "16:9", "9:16"],
                                        "default": "1:1",
                                        "description": "ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨"
                                    },
                                    "model": {
                                        "type": "string",
                                        "default": "imagegeneration@006",
                                        "description": "ì‚¬ìš©í•  Imagen ëª¨ë¸"
                                    },
                                    "seed": {
                                        "type": "integer",
                                        "description": "ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ê°’ (ì„ íƒì‚¬í•­)"
                                    },
                                    "safety_setting": {
                                        "type": "string",
                                        "default": "block_some",
                                        "description": "ì•ˆì „ í•„í„° ì„¤ì •"
                                    },
                                    "save_path": {
                                        "type": "string",
                                        "description": "ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ê²½ë¡œ (ì„ íƒì‚¬í•­)"
                                    },
                                    "filename_prefix": {
                                        "type": "string",
                                        "default": "generated_image",
                                        "description": "ì €ì¥í•  íŒŒì¼ëª… ì ‘ë‘ì‚¬"
                                    }
                                },
                                "required": ["prompt"]
                            }
                        },
                        {
                            "name": "list_models",
                            "description": "ì‚¬ìš© ê°€ëŠ¥í•œ Imagen ëª¨ë¸ ëª©ë¡ ì¡°íšŒ",
                            "inputSchema": {
                                "type": "object",
                                "properties": {}
                            }
                        }
                    ]
                }
            }
        
        elif method == "tools/call":
            tool_name = params.get("name")
            tool_args = params.get("arguments", {})
            
            if tool_name == "generate_image":
                result = await handle_generate_image(tool_args)
            elif tool_name == "list_models":
                result = await handle_list_models()
            else:
                result = {
                    "content": [
                        {
                            "type": "text",
                            "text": f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}"
                        }
                    ]
                }
            
            return {
                "jsonrpc": "2.0",
                "id": message.get("id"),
                "result": result
            }
        
        else:
            return {
                "jsonrpc": "2.0",
                "id": message.get("id"),
                "error": {"code": -32601, "message": f"ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì„œë“œ: {method}"}
            }
            
    except Exception as e:
        return {
            "jsonrpc": "2.0",
            "id": message.get("id"),
            "error": {"code": -32603, "message": f"ë‚´ë¶€ ì˜¤ë¥˜: {str(e)}"}
        }

async def stdio_server():
    """STDIO MCP ì„œë²„"""
    try:
        while True:
            # í‘œì¤€ ì…ë ¥ì—ì„œ ë©”ì‹œì§€ ì½ê¸°
            line = await asyncio.get_event_loop().run_in_executor(None, sys.stdin.readline)
            if not line:
                break
            
            line = line.strip()
            if not line:
                continue
            
            try:
                message = json.loads(line)
                response = await handle_message(message)
                
                # ì‘ë‹µì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶œë ¥ (notificationsëŠ” None ë°˜í™˜)
                if response is not None:
                    print(json.dumps(response), flush=True)
                
            except json.JSONDecodeError:
                # JSON ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
                continue
                
    except KeyboardInterrupt:
        pass
    except Exception:
        pass

async def interactive_mode():
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    print("ğŸ¨ Vertex AI Imagen MCP Server", file=sys.stderr)
    print("ëŒ€í™”í˜• ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.", file=sys.stderr)
    
    try:
        await initialize_client()
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ", file=sys.stderr)
        
        while True:
            try:
                print("\nğŸ“ ì´ë¯¸ì§€ ìƒì„± ì˜µì…˜:", file=sys.stderr)
                prompt = input("í”„ë¡¬í”„íŠ¸: ").strip()
                if not prompt:
                    break
                
                print(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘... ({prompt[:30]}...)", file=sys.stderr)
                
                result = await handle_generate_image({"prompt": prompt})
                
                if "error" in result:
                    print(f"âŒ {result['error']}", file=sys.stderr)
                else:
                    print(result["content"][0]["text"], file=sys.stderr)
                
                continue_choice = input("\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
                if continue_choice not in ['y', 'yes']:
                    break
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.", file=sys.stderr)
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {e}", file=sys.stderr)
                continue
                
    except Exception as e:
        print(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", file=sys.stderr)

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í‘œì¤€ ì…ë ¥ì´ í„°ë¯¸ë„ì¸ì§€ í™•ì¸
    if sys.stdin.isatty():
        # ëŒ€í™”í˜• ëª¨ë“œ
        await interactive_mode()
    else:
        # MCP STDIO ëª¨ë“œ
        await stdio_server()

if __name__ == "__main__":
    asyncio.run(main()) 